{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_Word2Vec_cleaned_text.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "azM2XHwelA1N",
        "AUbURRGgZAek",
        "5sVmB3P80NUz",
        "VCipOroM1g-2"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNGETYDkprU2JJM6EVt/Fei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b7ec3f91f1d466ca63f09adbc99de38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0664ed016e084fc682a1147c764803d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9244617c2a284cc8add476d266622cf5",
              "IPY_MODEL_b68140171a914882a2d647945a326d21"
            ]
          }
        },
        "0664ed016e084fc682a1147c764803d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9244617c2a284cc8add476d266622cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6aa2b1beae1242fcbbfd4bd7389cc992",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 356429,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 356429,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ea81fb0cd354ac7a1b1927674b3ea08"
          }
        },
        "b68140171a914882a2d647945a326d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4fa82bf0a54a4f95a1a63e9623968cc0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 356429/356429 [01:40&lt;00:00, 3540.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9e9ada6d77249bea2ecc0d889ebd687"
          }
        },
        "6aa2b1beae1242fcbbfd4bd7389cc992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ea81fb0cd354ac7a1b1927674b3ea08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fa82bf0a54a4f95a1a63e9623968cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9e9ada6d77249bea2ecc0d889ebd687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6855fc065314f8d9175d2773ee41da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2cad225c5eb4e4c86a5fe115cd02098",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_82f0027f40e44463befc0f87b45b336e",
              "IPY_MODEL_dedee9f17045470aa705f9f216d81d83"
            ]
          }
        },
        "f2cad225c5eb4e4c86a5fe115cd02098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82f0027f40e44463befc0f87b45b336e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8ff21683896471bb0a147ff7d906a85",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 356429,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 356429,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09a3771d06c84167aadd5d4ec1ec7c52"
          }
        },
        "dedee9f17045470aa705f9f216d81d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8870e0ef7fa4e06844ffbd6f47d3a80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 356429/356429 [22:10&lt;00:00, 267.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbf69cd9a9ee4274939431c9d68f570e"
          }
        },
        "a8ff21683896471bb0a147ff7d906a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09a3771d06c84167aadd5d4ec1ec7c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8870e0ef7fa4e06844ffbd6f47d3a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbf69cd9a9ee4274939431c9d68f570e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awadell1/MLOnAGooseberryBush/blob/master/src/TF_Word2Vec_cleaned_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMpXC2csG0BC"
      },
      "source": [
        "#Warning: if you have a 8G RAM laptop, don't run it locally. This code will take up approximately 10G of RAM.\n",
        "#Highly recommend run it on google colab in GPU mode\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLnuKtp1DvnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6c21c0-f655-488e-99c9-d59a6b978897"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm #create a progress bar\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-PUNVbnDjjO"
      },
      "source": [
        "import io\n",
        "import itertools\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkyvS2hPK0u7"
      },
      "source": [
        "SEED = 42 #setting the seed for reproducebility\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE #currently not entirely sure what this can do"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk14vEKCD6s6"
      },
      "source": [
        "def sentence_printout(path):\n",
        "    #just to demonstrate the txt file (the first ten sentence)\n",
        "    sentence=[]\n",
        "    with open(path) as f: \n",
        "        lines = f.read().splitlines()\n",
        "    sentence = []\n",
        "    for line in lines:\n",
        "        filter(None, line.split('\\t'))\n",
        "        sentence.append(list(filter(None, line.split('\\t'))))\n",
        "    f.close()\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRA7T-pTsU0r"
      },
      "source": [
        "sentence=sentence_printout(path='/content/drive/MyDrive/24787 Group Project  /Data/for_final_submission/description_sentence_cleaned.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJBQJEfYl4_l"
      },
      "source": [
        "I2W_df=pd.read_csv('/content/drive/MyDrive/24787 Group Project  /Data/for_final_submission/Dictionary_cleaned.csv')\n",
        "I2W=I2W_df.to_dict(orient='dict')['Vocab']\n",
        "I2W[0] = ''\n",
        "W2I = {v: k for k, v in I2W.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUYA8fzv5GCU"
      },
      "source": [
        "def sentence_to_indices(data,w2ind):\n",
        "    sentences_num=[]\n",
        "    for row in tqdm(data):\n",
        "        temp_mem=[w2ind[word] for word in row]\n",
        "        sentences_num.append(temp_mem)\n",
        "    return sentences_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9b7ec3f91f1d466ca63f09adbc99de38",
            "0664ed016e084fc682a1147c764803d0",
            "9244617c2a284cc8add476d266622cf5",
            "b68140171a914882a2d647945a326d21",
            "6aa2b1beae1242fcbbfd4bd7389cc992",
            "8ea81fb0cd354ac7a1b1927674b3ea08",
            "4fa82bf0a54a4f95a1a63e9623968cc0",
            "f9e9ada6d77249bea2ecc0d889ebd687"
          ]
        },
        "id": "d5rHDhJY5Hms",
        "outputId": "f52b5d59-d2cc-448a-9b51-20c8f93fd6b1"
      },
      "source": [
        "sentences_num = sentence_to_indices(data=sentence,w2ind=W2I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b7ec3f91f1d466ca63f09adbc99de38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=356429.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xby3gfDr5KHe",
        "outputId": "0ec7120e-3c85-461d-933d-378b05516bee"
      },
      "source": [
        "max_sentence_length= max([len(seq) for seq in sentences_num])\n",
        "max_sentence_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d-fAfP95L2z",
        "outputId": "03984bda-6d6e-4c30-d448-bd60811a48b0"
      },
      "source": [
        "for seq in sentences_num[:2]:\n",
        "  print(f\"{seq} \\n => \\n {[I2W[i] for i in seq]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15, 874, 202, 13, 1981, 3598, 1, 88, 105] \n",
            " => \n",
            " ['aromas', 'include', 'tropical', 'fruit', 'broom', 'brimstone', 'and', 'dried', 'herb']\n",
            "[2, 16, 909, 1031, 928, 308, 13741, 48, 60, 1, 88, 421, 142, 360, 18] \n",
            " => \n",
            " ['the', 'palate', \"isn't\", 'overly', 'expressive', 'offering', 'unripened', 'apple', 'citrus', 'and', 'dried', 'sage', 'alongside', 'brisk', 'acidity']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kORv-oIP5Z0f"
      },
      "source": [
        "#this function could be a bit confusing. The core idea of this function is to generate train data. \n",
        "#you can think of this as: \n",
        "#now, we have the description encoded as the above vector\n",
        "#we want to generate the target word (the word we select) and context word (the word we want to predict)\n",
        "#this function not only use positive skip gram but also use negative sampling\n",
        "#positive skip gram: target word + correct context word \n",
        "#negative sampling: target word + some random word selected from the dictonary (garanteed not in the context)\n",
        "\n",
        "#the label will be [1,0,0,0,0]\n",
        "#the first label is the saying the context word is the correct prediction\n",
        "#the number of 0 dependes on how many negative samples you want to generate\n",
        "\n",
        "\n",
        "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
        "# (int-encoded sentences) based on window size, number of negative samples\n",
        "# and vocabulary size.\n",
        "\n",
        "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
        "  # Elements of each training example are appended to these lists.\n",
        "  targets, contexts, labels = [], [], []\n",
        "\n",
        "  # Build the sampling table for vocab_size tokens.\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "  # Iterate over all sequences (sentences) in dataset.\n",
        "  for sequence in tqdm(sequences):\n",
        "\n",
        "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "          sequence, \n",
        "          vocabulary_size=vocab_size,\n",
        "          sampling_table=sampling_table,\n",
        "          window_size=window_size,\n",
        "          negative_samples=0)\n",
        "\n",
        "    # Iterate over each positive skip-gram pair to produce training examples \n",
        "    # with positive context word and negative samples.\n",
        "    for target_word, context_word in positive_skip_grams:\n",
        "      target_word = tf.cast(target_word,dtype='int64')\n",
        "      context_class = tf.expand_dims(\n",
        "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "          true_classes=context_class,\n",
        "          num_true=1, \n",
        "          num_sampled=num_ns, \n",
        "          unique=True, \n",
        "          range_max=vocab_size, \n",
        "          seed=SEED, \n",
        "          name=\"negative_sampling\")\n",
        "\n",
        "      # Build context and label vectors (for one target word)\n",
        "      negative_sampling_candidates = tf.expand_dims(\n",
        "          negative_sampling_candidates, 1)\n",
        "\n",
        "      context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
        "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "      # Append each element from the training example to global lists.\n",
        "      targets.append(target_word)\n",
        "      contexts.append(context)\n",
        "      labels.append(label)\n",
        "\n",
        "  return targets, contexts, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e6855fc065314f8d9175d2773ee41da9",
            "f2cad225c5eb4e4c86a5fe115cd02098",
            "82f0027f40e44463befc0f87b45b336e",
            "dedee9f17045470aa705f9f216d81d83",
            "a8ff21683896471bb0a147ff7d906a85",
            "09a3771d06c84167aadd5d4ec1ec7c52",
            "e8870e0ef7fa4e06844ffbd6f47d3a80",
            "fbf69cd9a9ee4274939431c9d68f570e"
          ]
        },
        "id": "NirFUy7P5byz",
        "outputId": "cb55941b-7389-48eb-ead3-65e85ee2d846"
      },
      "source": [
        "#calling this function\n",
        "num_ns=3 #number of negative samples for each target word\n",
        "window_size=2 #how long is your window_size, a good visualization: https://www.tensorflow.org/tutorials/text/images/word2vec_negative_sampling.png\n",
        "vocab_size = len(W2I)\n",
        "targets, contexts, labels = generate_training_data(\n",
        "    sequences=sentences_num, \n",
        "    window_size=window_size, \n",
        "    num_ns=num_ns, \n",
        "    vocab_size=vocab_size, \n",
        "    seed=SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6855fc065314f8d9175d2773ee41da9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=356429.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi_ru-krqJyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c39c894-8a6a-499a-9d7d-803e661dd9ae"
      },
      "source": [
        "print(len(targets),len(contexts),len(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2385108 2385108 2385108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fARoEvH_IAx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5859aa5-dd9a-4f4a-d9bf-7f14746cb834"
      },
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "#this is some tensorflow data cleaning function\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: (((1024,), (1024, 4, 1)), (1024, 4)), types: ((tf.int64, tf.int64), tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THSJqhsEcNzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26717eea-991a-43ab-efba-53e6da1df319"
      },
      "source": [
        "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: (((1024,), (1024, 4, 1)), (1024, 4)), types: ((tf.int64, tf.int64), tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9T6_v4aUzWb"
      },
      "source": [
        "#this is the Word2Vec architecture \n",
        "#a detailed description can be found here: https://www.tensorflow.org/tutorials/text/word2vec\n",
        "class Word2Vec(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Word2Vec, self).__init__()\n",
        "    self.target_embedding = Embedding(vocab_size, \n",
        "                                      embedding_dim,\n",
        "                                      input_length=1,\n",
        "                                      name=\"w2v_embedding\", )\n",
        "    self.context_embedding = Embedding(vocab_size, \n",
        "                                       embedding_dim, \n",
        "                                       input_length=num_ns+1)\n",
        "    self.dots = Dot(axes=(3,2))\n",
        "    self.flatten = Flatten()\n",
        "\n",
        "  def call(self, pair):\n",
        "    target, context = pair\n",
        "    we = self.target_embedding(target)\n",
        "    ce = self.context_embedding(context)\n",
        "    dots = self.dots([ce, we])\n",
        "    return self.flatten(dots)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EdquKm55wyQ"
      },
      "source": [
        "part 1-1 100D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsQq99JBVN6b"
      },
      "source": [
        "#compling the model\n",
        "embedding_dim = 100\n",
        "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
        "word2vec.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV-aKL00Vlpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be8f0f3-0ed5-4a2f-e3aa-2847c3994279"
      },
      "source": [
        "word2vec.fit(dataset,epochs=60,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "2329/2329 [==============================] - 56s 24ms/step - loss: 1.0632 - accuracy: 0.5527\n",
            "Epoch 2/60\n",
            "2329/2329 [==============================] - 55s 24ms/step - loss: 0.8267 - accuracy: 0.6686\n",
            "Epoch 3/60\n",
            "2329/2329 [==============================] - 57s 24ms/step - loss: 0.7372 - accuracy: 0.7070\n",
            "Epoch 4/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.6759 - accuracy: 0.7330\n",
            "Epoch 5/60\n",
            "2329/2329 [==============================] - 57s 25ms/step - loss: 0.6281 - accuracy: 0.7535\n",
            "Epoch 6/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.5890 - accuracy: 0.7703\n",
            "Epoch 7/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.5565 - accuracy: 0.7840\n",
            "Epoch 8/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.5292 - accuracy: 0.7952\n",
            "Epoch 9/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.5062 - accuracy: 0.8047\n",
            "Epoch 10/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.4867 - accuracy: 0.8125\n",
            "Epoch 11/60\n",
            "2329/2329 [==============================] - 57s 25ms/step - loss: 0.4702 - accuracy: 0.8190\n",
            "Epoch 12/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.4560 - accuracy: 0.8245\n",
            "Epoch 13/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.4439 - accuracy: 0.8291\n",
            "Epoch 14/60\n",
            "2329/2329 [==============================] - 59s 25ms/step - loss: 0.4334 - accuracy: 0.8330\n",
            "Epoch 15/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.4242 - accuracy: 0.8363\n",
            "Epoch 16/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.4162 - accuracy: 0.8393\n",
            "Epoch 17/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.4091 - accuracy: 0.8418\n",
            "Epoch 18/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.4028 - accuracy: 0.8440\n",
            "Epoch 19/60\n",
            "2329/2329 [==============================] - 59s 25ms/step - loss: 0.3971 - accuracy: 0.8461\n",
            "Epoch 20/60\n",
            "2329/2329 [==============================] - 58s 25ms/step - loss: 0.3921 - accuracy: 0.8479\n",
            "Epoch 21/60\n",
            "2329/2329 [==============================] - 59s 25ms/step - loss: 0.3875 - accuracy: 0.8495\n",
            "Epoch 22/60\n",
            "2329/2329 [==============================] - 59s 25ms/step - loss: 0.3833 - accuracy: 0.8508\n",
            "Epoch 23/60\n",
            "2329/2329 [==============================] - 59s 25ms/step - loss: 0.3795 - accuracy: 0.8521\n",
            "Epoch 24/60\n",
            "2329/2329 [==============================] - 59s 25ms/step - loss: 0.3760 - accuracy: 0.8533\n",
            "Epoch 25/60\n",
            "2329/2329 [==============================] - 60s 26ms/step - loss: 0.3728 - accuracy: 0.8544\n",
            "Epoch 26/60\n",
            "2329/2329 [==============================] - 62s 27ms/step - loss: 0.3698 - accuracy: 0.8554\n",
            "Epoch 27/60\n",
            "2329/2329 [==============================] - 62s 27ms/step - loss: 0.3670 - accuracy: 0.8563\n",
            "Epoch 28/60\n",
            "2329/2329 [==============================] - 63s 27ms/step - loss: 0.3644 - accuracy: 0.8572\n",
            "Epoch 29/60\n",
            "2329/2329 [==============================] - 64s 27ms/step - loss: 0.3620 - accuracy: 0.8580\n",
            "Epoch 30/60\n",
            "2329/2329 [==============================] - 62s 27ms/step - loss: 0.3598 - accuracy: 0.8588\n",
            "Epoch 31/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3577 - accuracy: 0.8595\n",
            "Epoch 32/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3557 - accuracy: 0.8602\n",
            "Epoch 33/60\n",
            "2329/2329 [==============================] - 62s 27ms/step - loss: 0.3539 - accuracy: 0.8608\n",
            "Epoch 34/60\n",
            "2329/2329 [==============================] - 63s 27ms/step - loss: 0.3521 - accuracy: 0.8614\n",
            "Epoch 35/60\n",
            "2329/2329 [==============================] - 63s 27ms/step - loss: 0.3505 - accuracy: 0.8619\n",
            "Epoch 36/60\n",
            "2329/2329 [==============================] - 60s 26ms/step - loss: 0.3489 - accuracy: 0.8625\n",
            "Epoch 37/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3474 - accuracy: 0.8630\n",
            "Epoch 38/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3460 - accuracy: 0.8634\n",
            "Epoch 39/60\n",
            "2329/2329 [==============================] - 62s 26ms/step - loss: 0.3446 - accuracy: 0.8639\n",
            "Epoch 40/60\n",
            "2329/2329 [==============================] - 63s 27ms/step - loss: 0.3434 - accuracy: 0.8643\n",
            "Epoch 41/60\n",
            "2329/2329 [==============================] - 62s 27ms/step - loss: 0.3421 - accuracy: 0.8647\n",
            "Epoch 42/60\n",
            "2329/2329 [==============================] - 64s 27ms/step - loss: 0.3410 - accuracy: 0.8650\n",
            "Epoch 43/60\n",
            "2329/2329 [==============================] - 62s 27ms/step - loss: 0.3398 - accuracy: 0.8654\n",
            "Epoch 44/60\n",
            "2329/2329 [==============================] - 60s 26ms/step - loss: 0.3388 - accuracy: 0.8658\n",
            "Epoch 45/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3378 - accuracy: 0.8661\n",
            "Epoch 46/60\n",
            "2329/2329 [==============================] - 62s 27ms/step - loss: 0.3368 - accuracy: 0.8664\n",
            "Epoch 47/60\n",
            "2329/2329 [==============================] - 63s 27ms/step - loss: 0.3358 - accuracy: 0.8667\n",
            "Epoch 48/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3349 - accuracy: 0.8670\n",
            "Epoch 49/60\n",
            "2329/2329 [==============================] - 62s 26ms/step - loss: 0.3341 - accuracy: 0.8673\n",
            "Epoch 50/60\n",
            "2329/2329 [==============================] - 63s 27ms/step - loss: 0.3332 - accuracy: 0.8675\n",
            "Epoch 51/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3324 - accuracy: 0.8678\n",
            "Epoch 52/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3316 - accuracy: 0.8681\n",
            "Epoch 53/60\n",
            "2329/2329 [==============================] - 62s 27ms/step - loss: 0.3309 - accuracy: 0.8683\n",
            "Epoch 54/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3302 - accuracy: 0.8685\n",
            "Epoch 55/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3295 - accuracy: 0.8687\n",
            "Epoch 56/60\n",
            "2329/2329 [==============================] - 62s 26ms/step - loss: 0.3288 - accuracy: 0.8689\n",
            "Epoch 57/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3281 - accuracy: 0.8692\n",
            "Epoch 58/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3275 - accuracy: 0.8694\n",
            "Epoch 59/60\n",
            "2329/2329 [==============================] - 61s 26ms/step - loss: 0.3269 - accuracy: 0.8695\n",
            "Epoch 60/60\n",
            "2329/2329 [==============================] - 62s 26ms/step - loss: 0.3263 - accuracy: 0.8697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd237ae9f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQW9jPCEHu4P"
      },
      "source": [
        "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gblfEPaoHxxI"
      },
      "source": [
        "out_v = io.open('/content/drive/MyDrive/24787 Group Project  /Data/for_final_submission/vectors100_cleaned.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('/content/drive/MyDrive/24787 Group Project  /Data/for_final_submission/metadata100_cleaned.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in I2W.items():\n",
        "  if  index == 0: continue # skip 0, it's padding.\n",
        "  vec = weights[index] \n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIsRPylB6ZUL"
      },
      "source": [
        "part 1-2 300D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1-R1iiQ6Xpb"
      },
      "source": [
        "#compling the model\n",
        "embedding_dim = 300\n",
        "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
        "word2vec.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixvTN6996dWF",
        "outputId": "6a850530-2978-4059-9bef-6ded47db5b3f"
      },
      "source": [
        "#trained 25 epochs\n",
        "word2vec.fit(dataset,epochs=1,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2329/2329 [==============================] - 176s 75ms/step - loss: 0.2755 - accuracy: 0.8851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd0dd66f390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOmjGBQy6og9"
      },
      "source": [
        "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prktFBnY6n38"
      },
      "source": [
        "out_v = io.open('/content/drive/MyDrive/24787 Group Project  /Data/for_final_submission/vectors300_cleaned.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('/content/drive/MyDrive/24787 Group Project  /Data/for_final_submission/metadata300_cleaned.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in I2W.items():\n",
        "  if  index == 0: continue # skip 0, it's padding.\n",
        "  vec = weights[index] \n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}