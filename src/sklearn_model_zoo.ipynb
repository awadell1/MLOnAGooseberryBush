{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit (conda)",
      "metadata": {
        "interpreter": {
          "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
        }
      }
    },
    "colab": {
      "name": "SampleNotebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsAmmyLdvzd0"
      },
      "source": [
        "# Load Dataset\n",
        "import pandas\n",
        "import re\n",
        "\n",
        "# Load Kaggle Wine Dataset: https://www.kaggle.com/zynicide/wine-reviews\n",
        "try:\n",
        "  wine_reviews = pandas.read_csv(\"../data/winemag-data-130k-v2.csv\")\n",
        "except:\n",
        "  wine_reviews = pandas.read_csv(\"https://drive.google.com/uc?export=download&id=1UFKyzq8aTg-1hgYVxVA0bm7D2mmKqSk9\")\n",
        "\n",
        "# Parse Year from Title\n",
        "year = []\n",
        "for title in wine_reviews.title:\n",
        "    year_match = re.search(\"(\\d{4})\", title)\n",
        "    if year_match:\n",
        "        year.append(year_match.group(1))\n",
        "    else:\n",
        "        year.append(None)\n",
        "\n",
        "wine_reviews.insert(wine_reviews.shape[1], value=year, column=\"year\")\n",
        "\n",
        "# Drop incomplete data\n",
        "wine_reviews.drop(columns=\"Unnamed: 0\", inplace=True)\n",
        "wine_reviews.dropna(axis=0, inplace=True)\n",
        "\n",
        "# Correct Data Types\n",
        "wine_reviews = wine_reviews.astype({\n",
        "    \"country\": \"category\",\n",
        "    \"description\": \"string\",\n",
        "    \"designation\": \"category\",\n",
        "    \"points\": \"int64\",\n",
        "    \"price\": \"float64\",\n",
        "    \"province\": \"category\",\n",
        "    \"region_1\": \"category\",\n",
        "    \"region_2\": \"category\",\n",
        "    \"taster_name\": \"category\",\n",
        "    \"taster_twitter_handle\": \"category\",\n",
        "    \"title\": \"string\",\n",
        "    \"variety\": \"category\",\n",
        "    \"winery\": \"category\",\n",
        "    \"year\": \"int64\",\n",
        "})"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRHkvsEZCa9"
      },
      "source": [
        "# Transfom and Featurize Data\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Build list of column transformers\n",
        "col_tf = {}\n",
        "\n",
        "# Drop Points\n",
        "col_tf[\"standard\"] = [\n",
        "    (\"points\", \"drop\", make_column_selector(\"points\")),\n",
        "    (\"price\", PowerTransformer(method=\"box-cox\"), make_column_selector(\"price\")),\n",
        "    (\"year\", MinMaxScaler(), make_column_selector(\"year\")),\n",
        "    (\"taster\", \"drop\", make_column_selector(\"taster_*\")),\n",
        "]\n",
        "\n",
        "# Build OneHot and Ordinal Encoders for Catergorial Data\n",
        "col_tf[\"OneHotEncoder\"] = []\n",
        "col_tf[\"OrdinalEncoder\"] = []\n",
        "for feat in wine_reviews.select_dtypes(include=['category']).columns:\n",
        "    categories = wine_reviews[feat].unique()\n",
        "    onehot = OneHotEncoder(categories=[categories])\n",
        "    ordinal = OrdinalEncoder(categories=[categories])\n",
        "    col_tf[\"OneHotEncoder\"].append((feat, onehot, make_column_selector(feat)))\n",
        "    col_tf[\"OrdinalEncoder\"].append((feat, ordinal, make_column_selector(feat)))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYKsVzR5lO7f"
      },
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Sparse to Dense Transformer\n",
        "DenseTransformer = FunctionTransformer(\n",
        "    func = lambda x: x.toarray(),\n",
        "    accept_sparse=True,\n",
        ")\n",
        "\n",
        "# Requires Dense\n",
        "req_dense = [\n",
        "    \"GaussianProcessClassifier\",\n",
        "    \"GaussianProcessRegressor\",\n",
        "    \"QuadraticDiscriminantAnalysis\",\n",
        "]\n",
        "\n",
        "def add_dense_tf(steps):\n",
        "    if steps[-1][0] in req_dense:\n",
        "        steps.insert(-1, (\"DenseTransformer\", DenseTransformer))\n",
        "    return steps"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8WKuYEKW5ZC"
      },
      "source": [
        "# Preallocate a list of models to train\n",
        "models = []"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptJpqwmou-MY"
      },
      "source": [
        "# Try Various Classifers\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# One-Hot + Continous Data\n",
        "classifers = [\n",
        "    KNeighborsClassifier(),\n",
        "    LinearSVC(),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    SVC(kernel=\"poly\"),\n",
        "    SVC(kernel=\"sigmoid\"),\n",
        "    #GaussianProcessClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    #QuadraticDiscriminantAnalysis(),\n",
        "]\n",
        "\n",
        "for c in classifers:\n",
        "    steps = [\n",
        "        (\"Std&OneHot\", ColumnTransformer(col_tf[\"standard\"]+col_tf[\"OneHotEncoder\"])),\n",
        "        (type(c).__name__, c),\n",
        "    ]\n",
        "    steps = add_dense_tf(steps)\n",
        "    p = Pipeline(steps, verbose=True)\n",
        "    models.append(p)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpvklyHpaFVR"
      },
      "source": [
        "# Ordinal Classifers\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "\n",
        "# Build Pipeline - Catergorical Only\n",
        "steps = [\n",
        "    (\"OrdinalCatOnly\", ColumnTransformer(col_tf[\"OrdinalEncoder\"])),\n",
        "    (\"CateCategoricalNB\", CategoricalNB()),\n",
        "]\n",
        "steps = add_dense_tf(steps)\n",
        "p = Pipeline(steps, verbose=True)\n",
        "models.append(p)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6qUWh7MgecH"
      },
      "source": [
        "# Regression Models\n",
        "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "regressors = [\n",
        "    AdaBoostRegressor(),\n",
        "    RandomForestRegressor(),\n",
        "    #GaussianProcessRegressor(),\n",
        "    LinearRegression(),\n",
        "    Ridge(),\n",
        "    ElasticNet(),\n",
        "    Lasso(),\n",
        "    KNeighborsRegressor(),\n",
        "    LinearSVC(),\n",
        "    DecisionTreeRegressor(),\n",
        "]\n",
        "\n",
        "for r in regressors:\n",
        "    steps = [\n",
        "        (\"Std&OneHot\", ColumnTransformer(col_tf[\"standard\"]+col_tf[\"OneHotEncoder\"])),\n",
        "        (type(r).__name__, r),\n",
        "    ]\n",
        "    steps = add_dense_tf(steps)\n",
        "    p = Pipeline(steps, verbose=True)\n",
        "    models.append(p)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
        "\n",
        "def input_shape(tf, data):\n",
        "    tf2 = deepcopy(tf)\n",
        "    X = tf2.fit_transform(data)\n",
        "    return X.shape[1]\n",
        "\n",
        "# Preprocessor and Input Size\n",
        "preprocess = ColumnTransformer(col_tf[\"standard\"]+col_tf[\"OneHotEncoder\"])\n",
        "input_dim = input_shape(preprocess, wine_reviews)\n",
        "\n",
        "# Build Regression Model\n",
        "def mlp_regression():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(100, activation=\"relu\", input_dim=input_dim),\n",
        "        layers.Dense(100, activation=\"relu\"),\n",
        "        layers.Dense(1, activation=\"linear\"),\n",
        "    ])\n",
        "    model.compile(\n",
        "        keras.optimizers.Adam(),\n",
        "        loss=keras.losses.mean_squared_error,\n",
        "        metrics=[\n",
        "            keras.metrics.mean_squared_error,\n",
        "            keras.metrics.mean_absolute_error,\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "models.append(Pipeline([\n",
        "    (\"Std&OneHot\", preprocess),\n",
        "    (\"KerasRegressor\", KerasRegressor(build_fn=mlp_regression, epochs=2)),\n",
        "   ], verbose=True\n",
        "))\n",
        "\n",
        "# Build Regression Model\n",
        "def mlp_classifer():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(100, activation=\"relu\", input_dim=input_dim),\n",
        "        layers.Dense(100, activation=\"relu\"),\n",
        "        layers.Dense(3, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(\n",
        "        keras.optimizers.Adam(),\n",
        "        loss=keras.losses.categorical_crossentropy,\n",
        "        metrics=[\n",
        "            keras.metrics.categorical_accuracy,\n",
        "            \"accuracy\",\n",
        "        ],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "models.append(Pipeline([\n",
        "    (\"Std&OneHot\", preprocess),\n",
        "    (\"KerasClassifier\", KerasClassifier(build_fn=mlp_classifer, epochs=5)),\n",
        "   ], verbose=True\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNTjxzrNmpv4"
      },
      "source": [
        "# Build Label Pipelines\n",
        "label_pipe = {}\n",
        "\n",
        "def point_pipe(name, tf):\n",
        "    return ColumnTransformer([(name, tf, make_column_selector(\"points\"))])\n",
        "\n",
        "# Bin all scores\n",
        "label_pipe[\"Classifer\"] = point_pipe(\"BinScores\",\n",
        "    KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
        ")\n",
        "\n",
        "# Normalize Scores to a Gaussian\n",
        "label_pipe[\"Regression\"] = point_pipe(\"NormScores\", StandardScaler())\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCggz5xuNd3g"
      },
      "source": [
        "# Enable Verbose and Parallel Models\n",
        "for m in models:\n",
        "    for k in m.get_params(deep=True).keys():\n",
        "        new_param = {}\n",
        "        if re.match(\".*n_job\", k):\n",
        "            new_param[k] = -1\n",
        "        if re.match(\".*verbose\", k):\n",
        "            new_param[k] = True\n",
        "        if new_param:\n",
        "            m.set_params(**new_param)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAsZXwg6oejr"
      },
      "source": [
        "Models to Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiqlJE_7ohHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21728fb-5d72-4010-ebb8-b8980c580f57"
      },
      "source": [
        "models.reverse()\n",
        "for idx, m in enumerate(models):\n",
        "    label = \" -> \".join([s[0] for s in m.steps])\n",
        "    print(f\"{idx:3d}: {label}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0: Std&OneHot -> KerasClassifier\n  1: Std&OneHot -> KerasRegressor\n  2: Std&OneHot -> DecisionTreeRegressor\n  3: Std&OneHot -> LinearSVC\n  4: Std&OneHot -> KNeighborsRegressor\n  5: Std&OneHot -> Lasso\n  6: Std&OneHot -> ElasticNet\n  7: Std&OneHot -> Ridge\n  8: Std&OneHot -> LinearRegression\n  9: Std&OneHot -> RandomForestRegressor\n 10: Std&OneHot -> AdaBoostRegressor\n 11: OrdinalCatOnly -> CateCategoricalNB\n 12: Std&OneHot -> RandomForestClassifier\n 13: Std&OneHot -> DecisionTreeClassifier\n 14: Std&OneHot -> AdaBoostClassifier\n 15: Std&OneHot -> SVC\n 16: Std&OneHot -> SVC\n 17: Std&OneHot -> SVC\n 18: Std&OneHot -> LinearSVC\n 19: Std&OneHot -> KNeighborsClassifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZETnSCFFcuC7"
      },
      "source": [
        "Train Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6U7tF4Ucl2E",
        "outputId": "e73acf2d-26a6-4e00-d81a-0e59d3c12524",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "import re\n",
        "from sklearn.base import is_classifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "\n",
        "# Split into Test/Train Sets\n",
        "train, test = train_test_split(wine_reviews, test_size=0.2, shuffle=True)\n",
        "\n",
        "for model in models:\n",
        "    # Transform Labels based on Model Type\n",
        "    if is_classifier(model) or re.match(\".*classifier\", model.steps[-1][0], flags=re.IGNORECASE):\n",
        "        y_pipe = label_pipe[\"Classifer\"]\n",
        "        model_type = \"classifer\"\n",
        "    else:\n",
        "        y_pipe = label_pipe[\"Regression\"]\n",
        "        model_type = \"regression\"\n",
        "\n",
        "    trainY = y_pipe.fit_transform(train).ravel()\n",
        "    testY =  y_pipe.transform(test).ravel()\n",
        "\n",
        "    model_name = model.steps[-1][0]\n",
        "    print(f\"\\nTraining: {model_name} - {model_type}\")\n",
        "\n",
        "    try:\n",
        "        model.fit(train, trainY)\n",
        "        if model_type is \"classifer\":\n",
        "            print(f\"Train: {model.score(train, trainY)}\")\n",
        "            print(f\"Test: {model.score(test, testY)}\")\n",
        "        else:\n",
        "            print(f\"Train: {mean_squared_error(trainY, model.predict(train))} - MSE\")\n",
        "            print(f\"Test: {mean_squared_error(testY, model.predict(test))} - MSE\")\n",
        "\n",
        "    except:\n",
        "        print(f\"Error Training Model\")\n",
        "        print(sys.exc_info())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training: KerasClassifier - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   2.0s\n",
            "Epoch 1/5\n",
            "552/552 [==============================] - 2s 4ms/step - loss: 0.5339 - categorical_accuracy: 0.7968 - accuracy: 0.7968\n",
            "Epoch 2/5\n",
            "552/552 [==============================] - 2s 4ms/step - loss: 0.3756 - categorical_accuracy: 0.8391 - accuracy: 0.8391\n",
            "Epoch 3/5\n",
            "552/552 [==============================] - 2s 4ms/step - loss: 0.2755 - categorical_accuracy: 0.8816 - accuracy: 0.8816\n",
            "Epoch 4/5\n",
            "552/552 [==============================] - 2s 4ms/step - loss: 0.2161 - categorical_accuracy: 0.9057 - accuracy: 0.9057\n",
            "Epoch 5/5\n",
            "552/552 [==============================] - 2s 4ms/step - loss: 0.1789 - categorical_accuracy: 0.9161 - accuracy: 0.9161\n",
            "[Pipeline] ... (step 2 of 2) Processing KerasClassifier, total=  12.4s\n",
            "552/552 [==============================] - 0s 716us/step - loss: 0.1350 - categorical_accuracy: 0.9393 - accuracy: 0.9393\n",
            "Train: 0.9392753839492798\n",
            "138/138 [==============================] - 0s 746us/step - loss: 0.6632 - categorical_accuracy: 0.7918 - accuracy: 0.7918\n",
            "Test: 0.7918367385864258\n",
            "\n",
            "Training: KerasRegressor - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "Epoch 1/2\n",
            "552/552 [==============================] - 2s 4ms/step - loss: 0.5958 - mean_squared_error: 0.5958 - mean_absolute_error: 0.6105\n",
            "Epoch 2/2\n",
            "552/552 [==============================] - 2s 4ms/step - loss: 0.3803 - mean_squared_error: 0.3803 - mean_absolute_error: 0.4743\n",
            "[Pipeline] .... (step 2 of 2) Processing KerasRegressor, total=   5.2s\n",
            "Train: 0.2612545411890727 - MSE\n",
            "Test: 0.4949578826285108 - MSE\n",
            "\n",
            "Training: DecisionTreeRegressor - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline]  (step 2 of 2) Processing DecisionTreeRegressor, total=   3.9s\n",
            "Train: 0.00023300095302142864 - MSE\n",
            "Test: 0.7463288368524216 - MSE\n",
            "\n",
            "Training: LinearSVC - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[LibLinear][Pipeline] ......... (step 2 of 2) Processing LinearSVC, total=   0.7s\n",
            "Train: 0.9250439417134433\n",
            "Test: 0.7986394557823129\n",
            "\n",
            "Training: KNeighborsRegressor - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline]  (step 2 of 2) Processing KNeighborsRegressor, total=   0.0s\n",
            "Train: 0.37779562402405686 - MSE\n",
            "Test: 0.5634855128380211 - MSE\n",
            "\n",
            "Training: Lasso - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline] ............. (step 2 of 2) Processing Lasso, total=   0.5s\n",
            "Train: 1.0000000000000004 - MSE\n",
            "Test: 0.9771464226079075 - MSE\n",
            "\n",
            "Training: ElasticNet - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline] ........ (step 2 of 2) Processing ElasticNet, total=   0.6s\n",
            "Train: 0.9911035222563256 - MSE\n",
            "Test: 0.9683984641045701 - MSE\n",
            "\n",
            "Training: Ridge - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline] ............. (step 2 of 2) Processing Ridge, total=   0.1s\n",
            "Train: 0.21936426526222205 - MSE\n",
            "Test: 0.4917634296128972 - MSE\n",
            "\n",
            "Training: LinearRegression - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline] .. (step 2 of 2) Processing LinearRegression, total=   4.2s\n",
            "Train: 0.15459245510852143 - MSE\n",
            "Test: 0.728306373291478 - MSE\n",
            "\n",
            "Training: RandomForestRegressor - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   41.8s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Pipeline]  (step 2 of 2) Processing RandomForestRegressor, total=  42.0s\n",
            "Train: 0.07211256264466467 - MSE\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "Test: 0.49474794573542386 - MSE\n",
            "\n",
            "Training: AdaBoostRegressor - regression\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline] . (step 2 of 2) Processing AdaBoostRegressor, total=   1.5s\n",
            "Train: 0.7185290658635751 - MSE\n",
            "Test: 0.7160809921143338 - MSE\n",
            "\n",
            "Training: CateCategoricalNB - classifer\n",
            "[Pipeline] .... (step 1 of 2) Processing OrdinalCatOnly, total=   0.0s\n",
            "[Pipeline] . (step 2 of 2) Processing CateCategoricalNB, total=   0.0s\n",
            "Train: 0.8296195498100584\n",
            "Error Training Model\n",
            "(<class 'IndexError'>, IndexError('index 180 is out of bounds for axis 1 with size 180'), <traceback object at 0x00000151F612B1C8>)\n",
            "\n",
            "Training: RandomForestClassifier - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.8s finished\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Pipeline]  (step 2 of 2) Processing RandomForestClassifier, total=   7.1s\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "Train: 0.9997165050745591\n",
            "Test: 0.8188208616780045\n",
            "\n",
            "Training: DecisionTreeClassifier - classifer\n",
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline]  (step 2 of 2) Processing DecisionTreeClassifier, total=   2.3s\n",
            "Train: 0.9997732040596473\n",
            "Test: 0.7902494331065759\n",
            "\n",
            "Training: AdaBoostClassifier - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline]  (step 2 of 2) Processing AdaBoostClassifier, total=   8.4s\n",
            "Train: 0.7888529795316663\n",
            "Test: 0.7934240362811792\n",
            "\n",
            "Training: SVC - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[LibSVM][Pipeline] ............... (step 2 of 2) Processing SVC, total=   6.5s\n",
            "Train: 0.7315870045926178\n",
            "Test: 0.7294784580498866\n",
            "\n",
            "Training: SVC - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[LibSVM][Pipeline] ............... (step 2 of 2) Processing SVC, total=  22.5s\n",
            "Train: 0.855644383965527\n",
            "Test: 0.8204081632653061\n",
            "\n",
            "Training: SVC - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[LibSVM][Pipeline] ............... (step 2 of 2) Processing SVC, total=  20.5s\n",
            "Train: 0.827464988376708\n",
            "Test: 0.8147392290249433\n",
            "\n",
            "Training: LinearSVC - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[LibLinear][Pipeline] ......... (step 2 of 2) Processing LinearSVC, total=   0.8s\n",
            "Train: 0.9250439417134433\n",
            "Test: 0.7986394557823129\n",
            "\n",
            "Training: KNeighborsClassifier - classifer\n",
            "[Pipeline] ........ (step 1 of 2) Processing Std&OneHot, total=   0.1s\n",
            "[Pipeline]  (step 2 of 2) Processing KNeighborsClassifier, total=   0.0s\n",
            "Train: 0.8436808981119238\n",
            "Test: 0.7945578231292517\n"
          ]
        }
      ]
    },
    {
      "source": [
        "Save Trained Models to Disk"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "for model in models:\n",
        "    model_name = model.steps[-1][0]\n",
        "    model_file = Path(\"../models\", model_name)\n",
        "    try:\n",
        "        with open(model_file.with_suffix(\".pickle\"), \"wb\") as file:\n",
        "            pickle.dump(model, file)\n",
        "    except:\n",
        "        # Rm empty file\n",
        "        model_file.with_suffix(\".pickle\").unlink()\n",
        "\n",
        "        # Save Keras Model\n",
        "        model.steps[-1][1].model.save(model_file.with_suffix(\".h5\"))"
      ]
    }
  ]
}