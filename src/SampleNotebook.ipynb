{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit (conda)",
      "metadata": {
        "interpreter": {
          "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
        }
      }
    },
    "colab": {
      "name": "SampleNotebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsAmmyLdvzd0"
      },
      "source": [
        "# Load Dataset\n",
        "import pandas\n",
        "import re\n",
        "\n",
        "# Load Kaggle Wine Dataset: https://www.kaggle.com/zynicide/wine-reviews\n",
        "try:\n",
        "  wine_reviews = pandas.read_csv(\"../data/winemag-data-130k-v2.csv\")\n",
        "except:\n",
        "  wine_reviews = pandas.read_csv(\"https://drive.google.com/uc?export=download&id=1UFKyzq8aTg-1hgYVxVA0bm7D2mmKqSk9\")\n",
        "\n",
        "# Parse Year from Title\n",
        "year = []\n",
        "for title in wine_reviews.title:\n",
        "    year_match = re.search(\"(\\d{4})\", title)\n",
        "    if year_match:\n",
        "        year.append(year_match.group(1))\n",
        "    else:\n",
        "        year.append(None)\n",
        "\n",
        "wine_reviews.insert(wine_reviews.shape[1], value=year, column=\"year\")\n",
        "\n",
        "# Drop incomplete data\n",
        "wine_reviews.drop(columns=\"Unnamed: 0\", inplace=True)\n",
        "wine_reviews.dropna(axis=0, inplace=True)\n",
        "\n",
        "# Correct Data Types\n",
        "wine_reviews = wine_reviews.astype({\n",
        "    \"country\": \"category\",\n",
        "    \"description\": \"string\",\n",
        "    \"designation\": \"category\",\n",
        "    \"points\": \"int64\",\n",
        "    \"price\": \"float64\",\n",
        "    \"province\": \"category\",\n",
        "    \"region_1\": \"category\",\n",
        "    \"region_2\": \"category\",\n",
        "    \"taster_name\": \"category\",\n",
        "    \"taster_twitter_handle\": \"category\",\n",
        "    \"title\": \"string\",\n",
        "    \"variety\": \"category\",\n",
        "    \"winery\": \"category\",\n",
        "    \"year\": \"int64\",\n",
        "})"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRHkvsEZCa9"
      },
      "source": [
        "# Transfom and Featurize Data\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Build list of column transformers\n",
        "col_tf = {}\n",
        "\n",
        "# Drop Points\n",
        "col_tf[\"standard\"] = [\n",
        "    (\"dropPoints\", \"drop\", make_column_selector(\"points\")),\n",
        "    (\"PowerTransform\", PowerTransformer(), make_column_selector(\"price\")),\n",
        "    (\"MinMaxScaler\", MinMaxScaler(), make_column_selector(\"year\")),\n",
        "    (\"dropTaster\", \"drop\", make_column_selector(\"taster_*\")),\n",
        "]\n",
        "\n",
        "# Build OneHot and Ordinal Encoders for Catergorial Data\n",
        "col_tf[\"OneHotEncoder\"] = []\n",
        "col_tf[\"OrdinalEncoder\"] = []\n",
        "for feat in wine_reviews.select_dtypes(include=['category']).columns:\n",
        "    categories = wine_reviews[feat].unique()\n",
        "    onehot = OneHotEncoder(categories=[categories])\n",
        "    ordinal = OrdinalEncoder(categories=[categories])\n",
        "    col_tf[\"OneHotEncoder\"].append((f\"OneHotVector-{feat}\", onehot, make_column_selector(feat)))\n",
        "    col_tf[\"OrdinalEncoder\"].append((f\"OrdinalEncoder-{feat}\", ordinal, make_column_selector(feat)))\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8WKuYEKW5ZC"
      },
      "source": [
        "# Preallocate a list of models to train\n",
        "models = []"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptJpqwmou-MY"
      },
      "source": [
        "# Try Various Classifers\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# One-Hot + Continous Data\n",
        "classifers = [\n",
        "    KNeighborsClassifier(),\n",
        "    LinearSVC(),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    SVC(kernel=\"poly\"),\n",
        "    SVC(kernel=\"sigmoid\"),\n",
        "    GaussianProcessClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    MLPClassifier(hidden_layer_sizes=(10000, 100,), activation=\"relu\"),\n",
        "]\n",
        "\n",
        "for c in classifers:\n",
        "    steps = [\n",
        "        (\"Featurize\", ColumnTransformer(col_tf[\"standard\"]+col_tf[\"OneHotEncoder\"])),\n",
        "        (type(c).__name__, c),\n",
        "    ]\n",
        "    p = Pipeline(steps, verbose=True)\n",
        "    models.append(p)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpvklyHpaFVR"
      },
      "source": [
        "# Ordinal Classifers\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "\n",
        "# Restrict to catergorical (Will Nullify Most of col_tf[\"standard\"])\n",
        "catOnly = (\"catOnly\", \"drop\", make_column_selector(dtype_include=\"category\"))\n",
        "\n",
        "# Build Pipeline\n",
        "steps = [\n",
        "    (\"Featurize\", ColumnTransformer([catOnly]+col_tf[\"standard\"]+col_tf[\"OrdinalEncoder\"])),\n",
        "    (\"CateCategoricalNB\", CategoricalNB()),\n",
        "]\n",
        "p = Pipeline(steps, verbose=True)\n",
        "models.append(p)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6qUWh7MgecH"
      },
      "source": [
        "# Regression Models\n",
        "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "regressors = [\n",
        "    AdaBoostRegressor(),\n",
        "    RandomForestRegressor(),\n",
        "    GaussianProcessRegressor(),\n",
        "    LinearRegression(),\n",
        "    Ridge(),\n",
        "    ElasticNet(),\n",
        "    Lasso(),\n",
        "    KNeighborsRegressor(),\n",
        "    MLPRegressor(),\n",
        "    LinearSVC(),\n",
        "    DecisionTreeRegressor(),\n",
        "]\n",
        "\n",
        "for r in regressors:\n",
        "    steps = [\n",
        "        (\"Featurize\", ColumnTransformer(col_tf[\"standard\"]+col_tf[\"OneHotEncoder\"])),\n",
        "        (type(r).__name__, r),\n",
        "    ]\n",
        "    p = Pipeline(steps, verbose=True)\n",
        "    models.append(p)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNTjxzrNmpv4"
      },
      "source": [
        "# Build Label Pipelines\n",
        "label_pipe = {}\n",
        "\n",
        "def point_pipe(name, tf):\n",
        "    return ColumnTransformer([(name, tf, make_column_selector(\"points\"))])\n",
        "\n",
        "# Bin all scores\n",
        "label_pipe[\"Classifer\"] = point_pipe(\"BinScores\",\n",
        "    KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
        ")\n",
        "\n",
        "# Normalize Scores to a Gaussian\n",
        "label_pipe[\"Regression\"] = point_pipe(\"NormScores\", StandardScaler())\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFkh7tQugDM-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCggz5xuNd3g"
      },
      "source": [
        "# Enable Verbose and Parralell Models\n",
        "for m in models:\n",
        "    for k in m.get_params(deep=True).keys():\n",
        "        new_param = {}\n",
        "        if re.match(\".*n_job\", k):\n",
        "            new_param[k] = -1\n",
        "        if re.match(\".*verbose\", k):\n",
        "            new_param[k] = True\n",
        "        if new_param:\n",
        "            m.set_params(**new_param)\n"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZETnSCFFcuC7"
      },
      "source": [
        "Train Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6U7tF4Ucl2E",
        "outputId": "ecec0737-4bd3-4ef8-c695-1ac566dabecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.base import is_classifier\n",
        "\n",
        "# Split into Test/Train Sets\n",
        "train, test = train_test_split(wine_reviews, test_size=0.2, shuffle=True)\n",
        "\n",
        "for model in models:\n",
        "    # Transform Labels based on Model Type\n",
        "    if is_classifier(model):\n",
        "        y_pipe = label_pipe[\"Classifer\"]\n",
        "    else:\n",
        "        y_pipe = label_pipe[\"Regression\"]\n",
        "\n",
        "    Y = y_pipe.fit_transform(train).ravel()\n",
        "\n",
        "    print(\"Training: %s\" % model.steps[-1][0])\n",
        "    try:\n",
        "        model.fit(trainX, trainY)\n",
        "        print(f\"Train: {model.score(trainX, trainY)}\")\n",
        "        print(f\"Test: {model.score(testX, testY)}\")\n",
        "    except:\n",
        "        print(f\"Error Training Model\")\n",
        "        print(sys.exc_info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: KNeighborsClassifier\n",
            "[Pipeline] ......... (step 1 of 2) Processing Featurize, total=   1.7s\n",
            "[Pipeline]  (step 2 of 2) Processing KNeighborsClassifier, total=   0.0s\n",
            "Train: 0.7726370697964506\n",
            "Test: 0.6696145124716554\n",
            "Training: LinearSVC\n",
            "[Pipeline] ......... (step 1 of 2) Processing Featurize, total=   0.2s\n",
            "[LibLinear][Pipeline] ......... (step 2 of 2) Processing LinearSVC, total=   1.5s\n",
            "Train: 0.888926688212281\n",
            "Test: 0.6947845804988663\n",
            "Training: SVC\n",
            "[Pipeline] ......... (step 1 of 2) Processing Featurize, total=   0.2s\n",
            "[LibSVM][Pipeline] ............... (step 2 of 2) Processing SVC, total=  30.9s\n",
            "Train: 0.7876056018597267\n",
            "Test: 0.7090702947845805\n",
            "Training: SVC\n",
            "[Pipeline] ......... (step 1 of 2) Processing Featurize, total=   0.2s\n",
            "[LibSVM][Pipeline] ............... (step 2 of 2) Processing SVC, total=  34.8s\n",
            "Train: 0.8257073198389748\n",
            "Test: 0.7160997732426304\n",
            "Training: SVC\n",
            "[Pipeline] ......... (step 1 of 2) Processing Featurize, total=   0.2s\n",
            "[LibSVM]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}