{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit (conda)",
      "metadata": {
        "interpreter": {
          "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
        }
      }
    },
    "colab": {
      "name": "SampleNotebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsAmmyLdvzd0"
      },
      "source": [
        "# Load Dataset\n",
        "import pandas\n",
        "import re\n",
        "\n",
        "# Load Kaggle Wine Dataset: https://www.kaggle.com/zynicide/wine-reviews\n",
        "try:\n",
        "  wine_reviews = pandas.read_csv(\"../data/winemag-data-130k-v2.csv\")\n",
        "except:\n",
        "  wine_reviews = pandas.read_csv(\"https://drive.google.com/uc?export=download&id=1UFKyzq8aTg-1hgYVxVA0bm7D2mmKqSk9\")\n",
        "\n",
        "# Parse Year from Title\n",
        "year = []\n",
        "for title in wine_reviews.title:\n",
        "    year_match = re.search(\"(\\d{4})\", title)\n",
        "    if year_match:\n",
        "        year.append(year_match.group(1))\n",
        "    else:\n",
        "        year.append(None)\n",
        "\n",
        "wine_reviews.insert(wine_reviews.shape[1], value=year, column=\"year\")\n",
        "\n",
        "# Drop incomplete data\n",
        "wine_reviews.drop(columns=\"Unnamed: 0\", inplace=True)\n",
        "wine_reviews.dropna(axis=0, inplace=True)\n",
        "\n",
        "# Correct Data Types\n",
        "wine_reviews = wine_reviews.astype({\n",
        "    \"country\": \"category\",\n",
        "    \"description\": \"string\",\n",
        "    \"designation\": \"category\",\n",
        "    \"points\": \"int64\",\n",
        "    \"price\": \"float64\",\n",
        "    \"province\": \"category\",\n",
        "    \"region_1\": \"category\",\n",
        "    \"region_2\": \"category\",\n",
        "    \"taster_name\": \"category\",\n",
        "    \"taster_twitter_handle\": \"category\",\n",
        "    \"title\": \"string\",\n",
        "    \"variety\": \"category\",\n",
        "    \"winery\": \"category\",\n",
        "    \"year\": \"int64\",\n",
        "})"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRHkvsEZCa9"
      },
      "source": [
        "# Transfom and Featurize Data\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Build list of column transformers\n",
        "col_tf = {}\n",
        "\n",
        "# Drop Points\n",
        "col_tf[\"standard\"] = [\n",
        "    (\"dropPoints\", \"drop\", make_column_selector(\"points\")),\n",
        "    (\"PowerTransform\", PowerTransformer(), make_column_selector(\"price\")),\n",
        "    (\"MinMaxScaler\", MinMaxScaler(), make_column_selector(\"year\")),\n",
        "    (\"dropTaster\", \"drop\", make_column_selector(\"taster_*\")),\n",
        "]\n",
        "\n",
        "# Build OneHot and Ordinal Encoders for Catergorial Data\n",
        "col_tf[\"OneHotEncoder\"] = []\n",
        "col_tf[\"OrdinalEncoder\"] = []\n",
        "for feat in wine_reviews.select_dtypes(include=['category']).columns:\n",
        "    categories = wine_reviews[feat].unique()\n",
        "    onehot = OneHotEncoder(categories=[categories])\n",
        "    ordinal = OrdinalEncoder(categories=[categories])\n",
        "    col_tf[\"OneHotEncoder\"].append((f\"OneHotVector-{feat}\", onehot, make_column_selector(feat)))\n",
        "    col_tf[\"OrdinalEncoder\"].append((f\"OrdinalEncoder-{feat}\", ordinal, make_column_selector(feat)))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYKsVzR5lO7f"
      },
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Sparse to Dense Transformer\n",
        "DenseTransformer = FunctionTransformer(\n",
        "    func = lambda x: x.toarray(),\n",
        "    accept_sparse=True,\n",
        ")\n",
        "\n",
        "# Requires Dense\n",
        "req_dense = [\n",
        "    \"GaussianProcessClassifier\",\n",
        "    \"GaussianProcessRegressor\",\n",
        "    \"QuadraticDiscriminantAnalysis\",\n",
        "]\n",
        "\n",
        "def add_dense_tf(steps):\n",
        "    if steps[-1][0] in req_dense:\n",
        "        steps.insert(-1, (\"DenseTransformer\", DenseTransformer))\n",
        "    return steps"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8WKuYEKW5ZC"
      },
      "source": [
        "# Preallocate a list of models to train\n",
        "models = []"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptJpqwmou-MY"
      },
      "source": [
        "# Try Various Classifers\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# One-Hot + Continous Data\n",
        "classifers = [\n",
        "    KNeighborsClassifier(),\n",
        "    LinearSVC(),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    SVC(kernel=\"poly\"),\n",
        "    SVC(kernel=\"sigmoid\"),\n",
        "    GaussianProcessClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    MLPClassifier(hidden_layer_sizes=(10000, 100,), activation=\"relu\"),\n",
        "]\n",
        "\n",
        "for c in classifers:\n",
        "    steps = [\n",
        "        (\"Std&OneHot\", ColumnTransformer(col_tf[\"standard\"]+col_tf[\"OneHotEncoder\"])),\n",
        "        (type(c).__name__, c),\n",
        "    ]\n",
        "    steps = add_dense_tf(steps)\n",
        "    p = Pipeline(steps, verbose=True)\n",
        "    models.append(p)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpvklyHpaFVR"
      },
      "source": [
        "# Ordinal Classifers\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "\n",
        "# Restrict to catergorical (Will Nullify Most of col_tf[\"standard\"])\n",
        "catOnly = (\"catOnly\", \"drop\", make_column_selector(dtype_include=\"category\"))\n",
        "\n",
        "# Build Pipeline\n",
        "steps = [\n",
        "    (\"OrdinalCatOnly\", ColumnTransformer([catOnly]+col_tf[\"standard\"]+col_tf[\"OrdinalEncoder\"])),\n",
        "    (\"CateCategoricalNB\", CategoricalNB()),\n",
        "]\n",
        "steps = add_dense_tf(steps)\n",
        "p = Pipeline(steps, verbose=True)\n",
        "models.append(p)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6qUWh7MgecH"
      },
      "source": [
        "# Regression Models\n",
        "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "regressors = [\n",
        "    AdaBoostRegressor(),\n",
        "    RandomForestRegressor(),\n",
        "    GaussianProcessRegressor(),\n",
        "    LinearRegression(),\n",
        "    Ridge(),\n",
        "    ElasticNet(),\n",
        "    Lasso(),\n",
        "    KNeighborsRegressor(),\n",
        "    MLPRegressor(),\n",
        "    LinearSVC(),\n",
        "    DecisionTreeRegressor(),\n",
        "]\n",
        "\n",
        "for r in regressors:\n",
        "    steps = [\n",
        "        (\"Std&OneHot\", ColumnTransformer(col_tf[\"standard\"]+col_tf[\"OneHotEncoder\"])),\n",
        "        (type(r).__name__, r),\n",
        "    ]\n",
        "    steps = add_dense_tf(steps)\n",
        "    p = Pipeline(steps, verbose=True)\n",
        "    models.append(p)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNTjxzrNmpv4"
      },
      "source": [
        "# Build Label Pipelines\n",
        "label_pipe = {}\n",
        "\n",
        "def point_pipe(name, tf):\n",
        "    return ColumnTransformer([(name, tf, make_column_selector(\"points\"))])\n",
        "\n",
        "# Bin all scores\n",
        "label_pipe[\"Classifer\"] = point_pipe(\"BinScores\",\n",
        "    KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
        ")\n",
        "\n",
        "# Normalize Scores to a Gaussian\n",
        "label_pipe[\"Regression\"] = point_pipe(\"NormScores\", StandardScaler())\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFkh7tQugDM-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCggz5xuNd3g"
      },
      "source": [
        "# Enable Verbose and Parralell Models\n",
        "for m in models:\n",
        "    for k in m.get_params(deep=True).keys():\n",
        "        new_param = {}\n",
        "        if re.match(\".*n_job\", k):\n",
        "            new_param[k] = -1\n",
        "        if re.match(\".*verbose\", k):\n",
        "            new_param[k] = True\n",
        "        if new_param:\n",
        "            m.set_params(**new_param)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAsZXwg6oejr"
      },
      "source": [
        "Models to Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiqlJE_7ohHv",
        "outputId": "bdd9e879-4a25-4a3d-b7b3-a928486b3f63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for idx, m in enumerate(models):\n",
        "    label = \" -> \".join([s[0] for s in m.steps])\n",
        "    print(f\"{idx:3d}: {label}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0: Std&OneHot -> KNeighborsClassifier\n",
            "  1: Std&OneHot -> LinearSVC\n",
            "  2: Std&OneHot -> SVC\n",
            "  3: Std&OneHot -> SVC\n",
            "  4: Std&OneHot -> SVC\n",
            "  5: Std&OneHot -> DenseTransformer -> GaussianProcessClassifier\n",
            "  6: Std&OneHot -> AdaBoostClassifier\n",
            "  7: Std&OneHot -> DecisionTreeClassifier\n",
            "  8: Std&OneHot -> RandomForestClassifier\n",
            "  9: Std&OneHot -> QuadraticDiscriminantAnalysis\n",
            " 10: Std&OneHot -> MLPClassifier\n",
            " 11: OrdinalCatOnly -> CateCategoricalNB\n",
            " 12: Std&OneHot -> AdaBoostRegressor\n",
            " 13: Std&OneHot -> RandomForestRegressor\n",
            " 14: Std&OneHot -> DenseTransformer -> GaussianProcessRegressor\n",
            " 15: Std&OneHot -> LinearRegression\n",
            " 16: Std&OneHot -> Ridge\n",
            " 17: Std&OneHot -> ElasticNet\n",
            " 18: Std&OneHot -> Lasso\n",
            " 19: Std&OneHot -> KNeighborsRegressor\n",
            " 20: Std&OneHot -> MLPRegressor\n",
            " 21: Std&OneHot -> LinearSVC\n",
            " 22: Std&OneHot -> DecisionTreeRegressor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZETnSCFFcuC7"
      },
      "source": [
        "Train Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6U7tF4Ucl2E"
      },
      "source": [
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.base import is_classifier\n",
        "\n",
        "# Split into Test/Train Sets\n",
        "train, test = train_test_split(wine_reviews, test_size=0.2, shuffle=True)\n",
        "\n",
        "for model in models:\n",
        "    # Transform Labels based on Model Type\n",
        "    if is_classifier(model):\n",
        "        y_pipe = label_pipe[\"Classifer\"]\n",
        "    else:\n",
        "        y_pipe = label_pipe[\"Regression\"]\n",
        "\n",
        "    trainY = y_pipe.fit_transform(train).ravel()\n",
        "    testY =  y_pipe.fit_transform(test).ravel()\n",
        "\n",
        "    print(\"\\nTraining: %s\" % model.steps[-1][0])\n",
        "\n",
        "    try:\n",
        "        model.fit(train, trainY)\n",
        "        print(f\"Train: {model.score(train, trainY)}\")\n",
        "        print(f\"Test: {model.score(test, testY)}\")\n",
        "    except:\n",
        "        print(f\"Error Training Model\")\n",
        "        print(sys.exc_info())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}